# Amazone Bedrock GenAI LLM Project
## Incident Knownledge Base
<img src="images/jpg-incident-kb.jpg">

## Incident Agent
<img src="images/jpg-incident-agent.jpg"/>

### Incident Severity Level Classification
<img src="images/jpg-incident-severity-classification.jpg">

The image depicts a process for identifying severity level to respond to IT incidents. Here are the steps in the flowchart, broken down into bullet points:

* The process starts with an IT incident being opened. There are two options at this point:
* If Model classified as critical or major incident, then an alert 
* The possible severity levels are Critical ,Major ,Minor, Cosmetic
* Depending on the severity level of the incident, different actions are taken.
 
### Data Extraction from Unstructure to Structure.
<img src="images/jpg-data-extraction.jpg">

It involved a process that uses a Large Language Model (LLM) Generative AI model to extract data from resumes in PDF format. Here's a breakdown of the process in bullet points:

* The process starts with unstructured data in PDF format being ingested. This could include resumes in various formats and styles.
* The LLM Generative AI model then extracts data from the PDF files.
* The extracted data is then stored in a structured format, like a JSON file. This allows for easier organization and analysis of the information.
* It's important to note that  while this process can be effective,  resumes with  widely varying layouts or those that are scanned documents might  cause issues with accuracy.